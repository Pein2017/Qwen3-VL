extends: base.yaml

# Stage 0: LoRA on Aligner only (freeze LLM+ViT)

model:
  model: model_cache/models/Qwen/Qwen3-VL-4B-Instruct

template:
  max_pixels: 401408

prompts:
  scheme: B

tuner:
  train_type: lora
  use_swift_lora: false
  target_modules: [all-linear]
  freeze_llm: true
  freeze_vit: true
  freeze_aligner: false
  lora_rank: 8
  lora_alpha: 32
  lora_dropout: 0.1
  lora_bias: none

# two GPUs
training:
  output_dir: ./output/stage_0_lora_aligner
  run_name: r8a32-lr_5e-4-eff_batch_32
  add_version: true
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  packing: true
  optimizer: multimodal
  learning_rate: 5.0e-4
  aligner_lr: 5.0e-4
  num_train_epochs: 6
  
  gradient_accumulation_steps: 2
  
  # Eval & checkpointing
  eval_strategy: steps
  eval_steps: 20
  save_strategy: steps
  save_steps: 40
  save_total_limit: 2
  save_only_model: true
  
  # Verbose logging
  logging_dir: ./tb/10-20
  logging_steps: 10
  logging_first_step: false

data:
  dataset_num_proc: 8
  dataloader_num_workers: 8
  eval_dataset: [placeholder]

deepspeed:
  enabled: true
  config: zero2

custom:
  train_jsonl: data/ds_v2_full/train.jsonl
  val_jsonl: data/ds_v2_full/val.jsonl
  augment_prob: 0.0
  images_per_user_turn: 2
  dump_conversation_text: false