stage_a_paths:
  # - output_post/stage_a/挡风板安装检查_stage_a.jsonl
  # - output_post/stage_a/BBU接地线检查_stage_a.jsonl
  - output_post/stage_a/BBU线缆布放要求_stage_a.jsonl
seed: 17

model:
  model_name_or_path: model_cache/models/Qwen/Qwen3-32B
  # model_name_or_path: output/12-9/summary_merged/res_1024-last_6_with_irrelevant_summary
  torch_dtype: bfloat16
  device_map: auto
  attn_implementation: flash_attention_2  # Enable Flash Attention 2 for faster inference (requires flash-attn package)

guidance:
  path: output_post/stage_b/initial_guidance.json
  retention: 5
  reset_on_rerun: true

output:
  root: output_post/stage_b
  run_name: new_stage  # Distill run name; artifacts under {root}/{mission_name}/{run_name}/
  group_report: true

sampler:
  samples_per_decode: 1
  grid:
    - temperature: 0.4
      top_p: 0.9
      max_new_tokens: 1024
      seed: 43
      repetition_penalty: 1.05
      stop:
        - "assistant"
        - "<|im_end|>"
        - "<|endoftext|>"
        - "</s>"
    - temperature: 0.7
      top_p: 0.9
      max_new_tokens: 1024
      seed: null
      repetition_penalty: 1.05
      stop:
        - "assistant"
        - "<|im_end|>"
        - "<|endoftext|>"
        - "</s>"


reflection:
  decision_prompt_path: configs/prompts/stage_b_reflection_decision_prompt.txt
  ops_prompt_path: configs/prompts/stage_b_reflection_ops_prompt.txt
  batch_size: 16  # Debug: 保持较小批次，便于观察每次反思
  max_operations: 5  # Debug: 每次最多 3 条经验修改

  temperature: 0.1  # Higher temperature for more diverse guidance entries
  top_p: 0.9  # Higher top_p for more diverse sampling
  repetition_penalty: 1.05
  max_new_tokens: 12000  # Allow longer responses to avoid truncation (G1 case)
  max_reflection_length: 24000  # Larger packed context
  token_budget: 24000  # Allow larger packed context to avoid dropping records

selection:
  policy: top_label
  tie_break: temperature


manual_review:
  min_verdict_agreement: 0.67 # fraction of candidates sharing the same verdict

runner:
  epochs: 6 # Tiny smoke: 单轮
  # per_rank_rollout_batch_size: per-rank (per-device) batch size.
  # With 8 GPUs and per_rank_rollout_batch_size: 2, each global step processes up to 16 tickets (2 per rank).
  per_rank_rollout_batch_size: 4
  logging_steps: 256

stage_b_distillation:
  enabled: true

# Guidance lifecycle management (optional)
guidance_lifecycle:
  confidence_drop_threshold: 0.35  # Remove experiences below this confidence
  min_miss_before_drop: 3          # Require at least this many misses before removal
  enable_auto_cleanup: true        # Auto-cleanup at each epoch end
