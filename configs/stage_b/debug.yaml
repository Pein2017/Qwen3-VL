stage_a_paths:
  # - output_post/stage_a/挡风板安装检查_stage_a.jsonl
  # - output_post/stage_a/BBU接地线检查_stage_a.jsonl
  - output_post/stage_a/BBU安装方式检查（正装）_stage_a.jsonl
seed: 17
max_token_length: 12000
default_domain: bbu
jump_reflection: false
domain_map:
  "RRU安装检查": rru
  "RRU位置检查": rru
  "RRU线缆": rru

model:
  model_name_or_path: model_cache/models/Qwen/Qwen3-32B
  # model_name_or_path: output/12-23/summary_merged/epoch_2-bbu_rru-more_irrelevant-ocr
  torch_dtype: bfloat16
  device_map: auto
  attn_implementation: flash_attention_2  # Enable Flash Attention 2 for faster inference (requires flash-attn package)

guidance:
  path: output_post/stage_b/initial_guidance.json
  retention: 5
  reset_on_rerun: true

output:
  root: output_post/stage_b
  run_name: debug_rule_search  # Artifacts under {root}/{mission_name}/{run_name}/

rule_search:
  proposer_prompt_path: configs/prompts/stage_b_rule_search_proposer_prompt.txt
  reflect_size: 8
  num_candidate_rules: 2

  train_pool_size: 128
  eval_pool_size: 26

  gate:
    min_relative_error_reduction: 0.05
    max_changed_fraction: 0.05
    max_fp_rate_increase: 0.01
    bootstrap:
      iterations: 100
      min_prob: 0.4
      seed: 17

  early_stop:
    patience: 3

  # Train pool uses decode-grid for rollout + gate.
  train_sampler:
    samples_per_decode: 1
    max_prompt_tokens: 4096
    grid:
      - temperature: 0.3
        top_p: 0.9
        max_new_tokens: 1024
        seed: 43
        repetition_penalty: 1.05
  # Eval pool uses low-temp single decode.
  eval_sampler:
    samples_per_decode: 1
    max_prompt_tokens: 4096
    grid:
      - temperature: 0.1
        top_p: 0.9
        max_new_tokens: 1024
        seed: 43
        repetition_penalty: 1.05

# Reflection config required by schema (used for rule proposer in rule_search mode).
# Note: decision_prompt_path and ops_prompt_path are not used in rule_search mode.
reflection:
  decision_prompt_path: configs/prompts/stage_b_reflection_decision_prompt.txt
  ops_prompt_path: configs/prompts/stage_b_reflection_ops_prompt.txt
  batch_size: 16  # Debug: 保持较小批次，便于观察每次反思
  max_operations: 5  # Debug: 每次最多 3 条经验修改

  temperature: 0.1  # Higher temperature for more diverse guidance entries
  top_p: 0.9  # Higher top_p for more diverse sampling
  repetition_penalty: 1.05
  max_new_tokens: 12000  # Allow longer responses to avoid truncation (G1 case)

runner:
  epochs: 6  # Tiny smoke: 单轮
  # per_rank_rollout_batch_size: per-rank (per-device) batch size.
  # With 8 GPUs and per_rank_rollout_batch_size: 2, each global step processes up to 16 tickets (2 per rank).
  per_rank_rollout_batch_size: 4
  logging_steps: 256

stage_b_distillation:
  enabled: true
  distill_size: 2000
  distill_temperature: 0.1
