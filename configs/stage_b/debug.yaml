stage_a_paths:
  - output_post/stage_a/挡风板安装检查_stage_a.jsonl
seed: 17

model:
  model_name_or_path: model_cache/models/Qwen/Qwen3-32B
  torch_dtype: bfloat16

  device_map: auto

guidance:
  path: output_post/stage_b/initial_guidance.json
  retention: 5
  reset_on_rerun: true

output:
  root: output_post/stage_b
  run_name: distill_qwen32_teacher-concise-epoch-10  # Distill run name; artifacts under {root}/{run_name}/{mission}/
  group_report: true

sampler:
  samples_per_decode: 1
  grid:
    - temperature: 0.1
      top_p: 0.9
      max_new_tokens: 1024
      seed: 42
      repetition_penalty: 1.05
      stop:
        - "assistant"
        - "<|im_end|>"
        - "<|endoftext|>"
        - "</s>"
    - temperature: 0.4
      top_p: 0.9
      max_new_tokens: 1024
      seed: 43
      repetition_penalty: 1.05
      stop:
        - "assistant"
        - "<|im_end|>"
        - "<|endoftext|>"
        - "</s>"
    - temperature: 0.7
      top_p: 0.9
      max_new_tokens: 1024
      seed: null
      repetition_penalty: 1.05
      stop:
        - "assistant"
        - "<|im_end|>"
        - "<|endoftext|>"
        - "</s>"


reflection:
  prompt_path: configs/prompts/stage_b_reflection_prompt.txt
  batch_size: 128  # Debug: 保持较小批次，便于观察每次反思
  max_operations: 5  # Debug: 每次最多 3 条经验修改

  temperature: 0.001  # Higher temperature for more diverse guidance entries
  top_p: 0.9  # Higher top_p for more diverse sampling
  repetition_penalty: 1.05
  max_new_tokens: 12000  # Allow longer responses to avoid truncation (G1 case)
  max_reflection_length: 24000  # Larger packed context
  token_budget: 24000  # Allow larger packed context to avoid dropping records

selection:
  policy: top_label
  tie_break: temperature


manual_review:
  min_verdict_agreement: 0.8  # fraction of candidates sharing the same verdict

runner:
  epochs: 10 # Tiny smoke: 单轮
  rollout_batch_size: 16

stage_b_distillation:
  enabled: true

# Guidance lifecycle management (optional)
guidance_lifecycle:
  confidence_drop_threshold: 0.35  # Remove experiences below this confidence
  min_miss_before_drop: 3          # Require at least this many misses before removal
  enable_auto_cleanup: true        # Auto-cleanup at each epoch end
