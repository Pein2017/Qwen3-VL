mode: rule_search

stage_a_paths:
  - output_post/stage_a_bbu_rru_summary/BBU接地线检查_stage_a_merged.jsonl
  # - output_post/stage_a/BBU接地线检查_stage_a_merged.jsonl

seed: 17
default_domain: bbu

model:
  model_name_or_path: model_cache/models/Qwen/Qwen3-VL-8B-Instruct
  # model_name_or_path: output/12-9/summary_merged/res_1024-last_6_with_irrelevant_summary
  torch_dtype: bfloat16
  device_map: auto
  attn_implementation: flash_attention_2  # Enable Flash Attention 2 for faster inference (requires flash-attn package)


guidance:
  path: output_post/stage_b/initial_guidance.json
  retention: 5
  reset_on_rerun: true

output:
  root: output_post/stage_b
  run_name: 12-19-bbu-line-rule-search-validate_size-256
  group_report: true

rule_search:
  proposer_prompt_path: configs/prompts/stage_b_rule_search_proposer_prompt.txt
  reflect_size: 16
  num_candidate_rules: 3

  # Holdout is currently split only (no explicit holdout eval yet).
  holdout:
    default_fraction: 0.2
    per_mission:
      BBU接地线检查: 0.1
    seed: 17
    stratify_by_label: true

  # Larger validation set for a 2.2k-ticket mission.
  validate_size: 512
  validate_with_replacement: false

  gate:
    min_relative_error_reduction: 0.02
    min_changed_fraction: 0.01
    bootstrap:
      iterations: 400
      min_prob: 0.4
      seed: 17

  early_stop:
    patience: 5

  # Gate evaluation with fewer samples per ticket to speed up.
  eval_sampler:
    samples_per_decode: 1
    grid:
      - temperature: 0.3
        top_p: 0.9
        max_new_tokens: 1024
        seed: 43
        repetition_penalty: 1.05
      - temperature: 0.5
        top_p: 0.9
        max_new_tokens: 1024
        seed: 43
        repetition_penalty: 1.05
      - temperature: 0.7
        top_p: 0.9
        max_new_tokens: 1024
        seed: 43
        repetition_penalty: 1.05
# Reflection config required by schema (used for rule proposer in rule_search mode).
# Note: decision_prompt_path and ops_prompt_path are not used in rule_search mode.
reflection:
  decision_prompt_path: configs/prompts/stage_b_reflection_decision_prompt.txt
  ops_prompt_path: configs/prompts/stage_b_reflection_ops_prompt.txt
  batch_size: 32
  max_operations: 2
  temperature: 0.3
  top_p: 0.9
  repetition_penalty: 1.05
  max_new_tokens: 12000
  max_reflection_length: 24000
  token_budget: 24000

selection:
  policy: top_label
  tie_break: temperature

runner:
  # rule_search iterations; early_stop will end earlier if no-gain.
  epochs: 20
  per_rank_rollout_batch_size: 128
  logging_steps: 64

stage_b_distillation:
  enabled: true
