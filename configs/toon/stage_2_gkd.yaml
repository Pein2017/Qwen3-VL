extends: ../base.yaml

# Stage 2: LoRA on LLM (last 4 blocks), freeze ViT, train aligner, enable GKD + TOON output

rlhf:
  rlhf_type: gkd
  teacher_model: model_cache/models/Qwen/Qwen3-VL-4B-Instruct
  beta: 0.001
  sft_alpha: 1
  seq_kd: false
  lmbda: 0.0

model:
  model: output/toon/11-03/stage_1_gkd/v1-20251103-015814/gkd-eff_batch_32-toon/checkpoint-340

# LoRA + aligner/vision control mirrors stage_2_llm_lora but keeps aligner trainable

tuner:
  train_type: lora
  use_swift_lora: false
  freeze_llm: false
  freeze_vit: true
  freeze_aligner: false
  target_modules: [all-linear]
  target_regex: '^(?:model\.)?language_model\.layers\.(?:32|33|34|35)\.(?:self_attn\.(?:q_proj|k_proj|v_proj|o_proj)|mlp\.(?:gate_proj|up_proj|down_proj))$'
  modules_to_save:
    - model.visual.merger
    - model.visual.deepstack_merger_list.0
    - model.visual.deepstack_merger_list.1
    - model.visual.deepstack_merger_list.2
  lora_rank: 16
  lora_alpha: 32
  lora_dropout: 0.1
  lora_bias: none

training:
  output_dir: ./output/toon/11-03/stage_2_gkd/
  run_name: toon-lora_4-eff_batch_32-epoch_5-small_gkd_weights
  logging_dir: ./tb/toon/11-03/stage_2_gkd/
  per_device_train_batch_size: 2
  save_only_model: true
  optimizer: multimodal
  learning_rate: 5.0e-4
  vit_lr: 2.0e-5
  aligner_lr: 2.0e-4
  num_train_epochs: 5
  gradient_accumulation_steps: 2

  eval_strategy: steps
  save_strategy: best
  eval_steps: 20
  save_steps: 40
  save_total_limit: 2
  save_delay_steps: 200

data:
  dataset_num_proc: 8
  dataloader_num_workers: 8

custom:
  emit_norm: norm1000  # Explicit for TOON serialization
  visual_kd:
    enabled: true
    weight: 0.001  # Heavier anchor on vision/aligner (0.1-0.2 typical). Lower if visuals overfit.
    targets: [merger]
    distance: mse

  dump_conversation_text: false
  trainer_variant: gkd_monitor
  toon_mode: true

