extends: ../base.yaml

# Stage 1.5: DoRA on all LLM layers (q_proj & v_proj only), DoRA on last-12 Vision blocks (15-26, qkv only), DoRA on all aligner MLP layers

model:
  # Point to stage 2 best checkpoint - will load base model + LLM LoRA
  model: model_cache/models/Qwen/Qwen3-VL-8B-Instruct

tuner:
  train_type: lora
  use_swift_lora: false
  use_dora: true        # ← Enable DoRA (Weight-Decomposed Low-Rank Adaptation)
  freeze_llm: false     # ← Enable DoRA on all LLM layers (see target_regex below)
  freeze_vit: false     # ← Add DoRA to Vision last-12 blocks (15-26 for 8B model)
  freeze_aligner: false # ← Enable DoRA on all aligner modules
  target_modules: [all-linear]
  # LLM: all decoder layers, attention q_proj & v_proj only (no k_proj / o_proj, no MLP).
  # Vision: last-12 blocks (15-26), attention qkv only (no proj, no MLP).
  # Aligner: merger & deepstack_merger_list MLPs (linear_fc1/fc2) fully tuned with DoRA.
  target_regex: '^(?:model\.)?(?:language_model\.layers\.\d+\.self_attn\.(?:q_proj|v_proj)|visual\.blocks\.(?:15|16|17|18|19|20|21|22|23|24|25|26)\.attn\.qkv|visual\.(?:merger|deepstack_merger_list\.\d+)\.(?:linear_fc1|linear_fc2))$'
  
  modules_to_save: []  # All modules now use LoRA, none fully tuned
  lora_rank: 16
  lora_alpha: 32
  lora_dropout: 0.1
  lora_bias: none

rlhf:
  rlhf_type: gkd
  # Use a stable, cached teacher checkpoint; tests assert this lives under
  # ``model_cache/`` and is distinct from the student path.
  teacher_model: model_cache/models/Qwen/Qwen3-VL-8B-Instruct
  sft_alpha: 1.0
  llm_kd_weight: 0.01
  seq_kd: false
  lmbda: 0.0

training:
  # Paths and naming
  output_dir: ./output/11-21/stage_1.5
  run_name: lvis_ratio_0.08-epoch_30-dlora-lrs_4_2_8-llm_kd_0.01-vision_kd_0.01-last_12_vision-all_llm-from_base

  # Epochs and batch sizes
  num_train_epochs: 30
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 2
  # Auto-calculated from effective_batch_size, per_device_train_batch_size, and world_size
  # gradient_accumulation_steps: 8  # Commented out - now auto-calculated
  effective_batch_size: 32  # Will auto-calculate gradient_accumulation_steps to maintain this effective batch size
  
  # Optimizer and learning rates
  optimizer: multimodal
  learning_rate: 4.0e-4  
  vit_lr: 2.0e-4          
  aligner_lr: 8.0e-4     
  
  lr_scheduler_kwargs:
    min_lr: 1.0e-6
  
  # Training flags
  packing: true
  weight_decay: 0.1
  warmup_ratio: 0.1
  add_version: true
  save_safetensors: true
  
  # Eval and checkpointing
  eval_strategy: steps
  save_strategy: best
  eval_steps: 40
  save_steps: 10
  save_total_limit: 4
  save_delay_steps: 1800
  
  # Logging
  logging_dir: ./tb/11-21/stage_1.5
  logging_steps: 10
  logging_first_step: true

data:
  dataset_num_proc: 8
  dataloader_num_workers: 16
  dataloader_pin_memory: true
  dataloader_prefetch_factor: 4

deepspeed:
  enabled: true
  config: zero2

custom:
  trainer_variant: gkd_monitor
  visual_kd:
    enabled: true
    vit:
      enabled: true
      weight: 0.01
      distance: cosine
    aligner:
      enabled: true
      weight: 0.01  # Heavier anchor on vision/aligner (0.1-0.2 typical). Lower if visuals overfit.
      distance: cosine
    deepstack:
      enabled: true
      weight: 0.01
      distance: cosine
  emit_norm: norm1000
  dump_conversation_text: false
  fusion_config: configs/fusion/bbu_with_lvis.yaml
  # Augmentation pipeline (training only). Eval remains unchanged.
  # Soft augmentation: lower probabilities and less aggressive transforms
  augmentation:
    enabled: true
    bypass_prob: 0.1  # More clean samples (60% augmented, 40% clean)
    ops:
      # Geometric ops (soft probabilities and ranges)
      - name: hflip
        params: { prob: 0.2 }  # Reduced from 0.35
      - name: vflip
        params: { prob: 0.05 }  # Reduced from 0.12
      - name: rotate
        params: { max_deg: 10.0, prob: 0.15 }  # Reduced angle and prob from 15.0/0.3
      # Expand canvas to enclose rotated/scaled content (no information loss)
      - name: expand_to_fit_affine
        params: { multiple: 32 }
      - name: random_crop
        params:
          scale: [0.9, 1.0]               # Crop 90-100% of image (softer, less aggressive)
          aspect_ratio: [0.95, 1.05]      # Nearly square crops (tighter range)
          min_coverage: 0.4               # Drop objects <40% visible (more lenient)
          completeness_threshold: 0.95    # Mark "只显示部分" if <95% visible
          min_objects: 4                  # Skip crop if <4 objects (dense scenes)
          skip_if_line: true              # Skip crop if line objects present
          prob: 0.08                      # Reduced from 0.15 (softer)
      # ✅ Multi-scale training: prefer medium-large sizes (no aggressive shrinking)
      - name: resize_by_scale
        params: { lo: 0.98, hi: 1.05, align_multiple: 32, prob: 0.3 }  # Tighter range, lower prob
      # Color ops (soft intensity and probabilities)
      - name: color_jitter
        params: { brightness: [0.95, 1.05], contrast: [0.95, 1.05], saturation: [0.95, 1.05], prob: 0.15 }  # Reduced intensity and prob
      - name: gamma
        params: { gamma: [0.95, 1.05], prob: 0.08 }  # Reduced range and prob
      - name: hsv
        params: { hue_delta_deg: [-3, 3], sat: [0.98, 1.02], val: [0.98, 1.02], prob: 0.08 }  # Reduced intensity and prob
      - name: clahe
        params: { clip_limit: 1.5, tile_grid_size: [8, 8], prob: 0.05 }  # Reduced intensity and prob
      - name: auto_contrast
        params: { cutoff: 0, prob: 0.04 }  # Reduced prob
      # equalize removed - redundant with auto_contrast (both global histogram ops)
      - name: sharpness
        params: { factor: [0.95, 1.08], prob: 0.08 }  # Reduced range and prob
      # Note: pad_to_multiple removed - expand_to_fit_affine already handles it

  augmentation_curriculum:
    phases:
      # No augmentation: first 10% of training with clean data only
      - until_percent: 10
        bypass_prob: 1.0
        ops: {}

      # Warmup: mostly clean, very light geometry & color
      - until_percent: 20
        bypass_prob: 0.30
        ops:
          rotate:
            prob: 0.10
            max_deg: 8.0
          random_crop:
            prob: 0.05
            scale: [0.95, 1.00]
          resize_by_scale:
            prob: 0.20
            lo: 0.98
            hi: 1.03
          color_jitter:
            prob: 0.10
            brightness: [0.97, 1.03]
            contrast: [0.97, 1.03]
            saturation: [0.97, 1.03]

      # Early core: moderate geometry, still conservative crops/colors
      - until_percent: 45
        bypass_prob: 0.22
        ops:
          rotate:
            prob: 0.16
            max_deg: 10.0
          random_crop:
            prob: 0.08
            scale: [0.92, 0.99]
          resize_by_scale:
            prob: 0.30
            lo: 0.97
            hi: 1.05
          color_jitter:
            prob: 0.14
            brightness: [0.95, 1.05]
            contrast: [0.95, 1.05]
            saturation: [0.95, 1.05]

      # Main training: stronger but still smooth increases
      - until_percent: 70
        bypass_prob: 0.15
        ops:
          rotate:
            prob: 0.20
            max_deg: 12.0
          random_crop:
            prob: 0.10
            scale: [0.90, 0.98]
          resize_by_scale:
            prob: 0.36
            lo: 0.96
            hi: 1.06
          color_jitter:
            prob: 0.18
            brightness: [0.93, 1.07]
            contrast: [0.93, 1.07]
            saturation: [0.93, 1.07]
          hsv:
            prob: 0.06
            hue_delta_deg: [-3, 3]
            sat: [0.98, 1.02]
            val: [0.98, 1.02]

      # Late training: peak augmentation, smallest step from previous phase
      - until_percent: 100
        bypass_prob: 0.08
        ops:
          rotate:
            prob: 0.24
            max_deg: 14.0
          random_crop:
            prob: 0.12
            scale: [0.88, 0.98]
          resize_by_scale:
            prob: 0.40
            lo: 0.95
            hi: 1.07
          color_jitter:
            prob: 0.22
            brightness: [0.92, 1.08]
            contrast: [0.92, 1.08]
            saturation: [0.92, 1.08]
          hsv:
            prob: 0.08
            hue_delta_deg: [-4, 4]
            sat: [0.97, 1.03]
            val: [0.97, 1.03]
