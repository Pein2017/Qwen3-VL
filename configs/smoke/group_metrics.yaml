extends: ../fused_data/base_all.yaml

# Smoke configuration for fusion group metrics with 4B checkpoint.

model:
  model: model_cache/models/Qwen/Qwen3-VL-4B-Instruct

training:
  run_name: smoke_group_metrics_4b
  output_dir: ./output/smoke/group_metrics
  logging_dir: ./tb/smoke/group_metrics
  num_train_epochs: 2
  # Cap steps to keep the debug smoke run under control while still running
  # longer than the earlier short attempts.
  eval_strategy: steps
  save_strategy: "no"
  save_total_limit: 1
  logging_steps: 1          # smallest interval for quick feedback
  eval_steps: 1             # frequent eval in smoke setting
  log_level: debug
  log_level_replica: debug
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  effective_batch_size: 2

custom:
  # Keep tiny fusion mix and sample caps from debug base for fast turnaround
  fusion_config: configs/fusion/bbu_rru_lvis_coig_tiny.yaml
  train_sample_limit: 16
  val_sample_limit: 8
  token_type_metrics:
    enabled: true
    include: ["bbu", "rru", "lvis"]
    exclude: ["chat", "lang_chat", "coig_lang_chat"]
